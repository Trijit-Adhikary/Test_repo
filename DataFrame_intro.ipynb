{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19989269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port', '0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07318371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id,order_date,customer_id,order_status\n",
      "1,2013-07-25 00:00:00.0,11599,CLOSED\n",
      "2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT\n",
      "3,2013-07-25 00:00:00.0,12111,COMPLETE\n",
      "4,2013-07-25 00:00:00.0,8827,CLOSED\n",
      "5,2013-07-25 00:00:00.0,11318,COMPLETE\n",
      "6,2013-07-25 00:00:00.0,7130,COMPLETE\n",
      "7,2013-07-25 00:00:00.0,4530,COMPLETE\n",
      "8,2013-07-25 00:00:00.0,2911,PROCESSING\n",
      "9,2013-07-25 00:00:00.0,5657,PENDING_PAYMENT\n",
      "10,2013-07-25 00:00:00.0,5648,PENDING_PAYMENT\n",
      "11,2013-07-25 00:00:00.0,918,PAYMENT_REVIEW\n",
      "12,2013-07-25 00:00:00.0,1837,CLOSED\n",
      "13,2013-07-25 00:00:00.0,9149,PENDING_PAYMENT\n",
      "14,2013-07-25 00:00:00.0,9842,PROCESSING\n",
      "15,2013-07-25 00:00:00.0,2568,COMPLETE\n",
      "16,2013-07-25 00:00:00.0,7276,PENDING_PAYMENT\n",
      "17,2013-07-25 00:00:00.0,2667,COMPLETE\n",
      "18,2013-07-25 00:00:00.0,1205,CLOSED\n",
      "19,2013-07-25 00:00:00.0,9488,PENDING_PAYMENT\n",
      "20,2013-07-25 00:00:00.0,9198,PROCESSING\n",
      "21,2013-07-25 00:00:00.0,2711,PENDING\n",
      "22,2013-07-25 00:00:00.0,333,COMPLETE\n",
      "23,2013-07-25 00:00:00.0,4367,PENDING_PAYMENT\n",
      "24,2013-07-25 00:00:00.0,11441,CLOSED\n",
      "2"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -head /public/trendytech/orders_wh/orders_wh.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e69db15",
   "metadata": {},
   "source": [
    "# Standard way to create a Dataframe from a file -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c45984",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = spark.read.format(\"csv\")\\\n",
    ".option(\"inferschema\",\"true\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".load(\"/public/trendytech/orders_wh/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a46a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------+---------------+\n",
      "|order_id|order_date           |customer_id|order_status   |\n",
      "+--------+---------------------+-----------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599      |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256        |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111      |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827       |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318      |COMPLETE       |\n",
      "+--------+---------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa8f4aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3dbd1",
   "metadata": {},
   "source": [
    "# Renaming an existing column -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "361357dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------+---------------+\n",
      "|order_id|order_date           |customer_id|status         |\n",
      "+--------+---------------------+-----------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599      |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256        |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111      |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827       |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318      |COMPLETE       |\n",
      "+--------+---------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_col_renamed_df = order_df.withColumnRenamed(\"order_status\",\"status\")\n",
    "order_col_renamed_df.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54624c",
   "metadata": {},
   "source": [
    "# Convert String to timestamp -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49e3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3af35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- order_date_timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_date_timestamp_df = order_col_renamed_df.withColumn(\"order_date_timestamp\", to_timestamp(\"order_date\"))\n",
    "order_date_timestamp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86bfc9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------+---------------+--------------------+\n",
      "|order_id|order_date           |customer_id|status         |order_date_timestamp|\n",
      "+--------+---------------------+-----------+---------------+--------------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599      |CLOSED         |2013-07-25 00:00:00 |\n",
      "|2       |2013-07-25 00:00:00.0|256        |PENDING_PAYMENT|2013-07-25 00:00:00 |\n",
      "|3       |2013-07-25 00:00:00.0|12111      |COMPLETE       |2013-07-25 00:00:00 |\n",
      "|4       |2013-07-25 00:00:00.0|8827       |CLOSED         |2013-07-25 00:00:00 |\n",
      "|5       |2013-07-25 00:00:00.0|11318      |COMPLETE       |2013-07-25 00:00:00 |\n",
      "+--------+---------------------+-----------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_date_timestamp_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a5d713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
